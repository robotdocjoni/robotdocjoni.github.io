---
title: "Adaptation, Learning and Optimization with Human-Feedbacks"
excerpt: "Enhancing user experience and performance<br/><img src='/images/project-3_500x300.jpg'>"
collection: projects
---
My research in adaptation, learning, and optimization with human-feedback aims to advance the design of effective Human-Robot Interaction (HRI) and Human-Computer Interaction (HCI) systems. I focus on developing intelligent systems that learn and adapt based on human input and interaction, either offline, online, or in real-time. This work began with our project funded by the Sutherland Fellowship at the University of Sussex, which focused on human-in-the-loop PID control based on Continuous Actor-Critic Learning Automaton (CACLA) reinforcement learning [(Zhong & Li, 2019)](https://link.springer.com/chapter/10.1007/978-3-030-27535-8_54) and incremental learning frameworks for skeletal-based hand gesture recognition [(Li et al., 2019)](https://ieeexplore.ieee.org/abstract/document/9066761). These studies demonstrate my expertise in creating systems that optimize their performance through human feedback.

In a broader sense, my research on adaptive boosting for occupancy estimation using heat-maps [(Naser et al., 2020)](https://ieeexplore.ieee.org/abstract/document/9177685) and a human-in-the-loop system [(Naser et al., 2022)](https://ieeexplore.ieee.org/abstract/document/9882393) ensures that human-feedback optimization can be updated in a system. These works build upon seminal research in human-in-the-loop optimization, such as interactive machine learning [(Fails & Olsen, 2003)](https://3dvar.com/Fails2003Interactive.pdf), [reinforcement learning with human feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback#cite_note-ziegler-2), and [online reinforcement learning](https://huggingface.co/learn/deep-rl-course/en/unitbonus3/offline-online). The ultimate goal is to achieve closed-loop feedback assistive devices with multimodal human feedback, enabling seamless and efficient human-machine interaction.

By incorporating human feedback into the learning and optimization processes, these systems can adapt to individual preferences, improve performance, and provide a more personalized and engaging user experience. The integration of offline, online, and real-time learning approaches allows for continuous refinement and adaptation of the system based on user input. Through rigorous experimentation and evaluation, my research aims to advance the state-of-the-art in human-in-the-loop optimization and contribute to the development of intelligent, adaptive, and user-centric HRI and HCI systems.